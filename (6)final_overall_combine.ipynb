{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b96228-0482-4147-9b46-d7a26c5a3daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV columns: ['category', 'train_mean', 'train_std', 'threshold', 'image_AUROC', 'accuracy', 'n_test']\n",
      "\n",
      "Loaded thresholds for:\n",
      "bottle: 0.1071691784986634\n",
      "cable: 0.1449074127336039\n",
      "capsule: 0.0881808400108139\n",
      "carpet: 0.0585161529997106\n",
      "grid: 0.0914179283961397\n",
      "hazelnut: 0.1328290603011438\n",
      "leather: 0.0502316191441985\n",
      "metal_nut: 0.1131659973496359\n",
      "pill: 0.0923540407455983\n",
      "screw: 0.1081089502004047\n",
      "tile: 0.0905780693737589\n",
      "toothbrush: 0.1283455279455947\n",
      "transistor: 0.1239226004720422\n",
      "wood: 0.0961848321741979\n",
      "zipper: 0.0660800238644721\n",
      "\n",
      "Saved thresholds.json to: saved_spatial_caes_simple/thresholds.json\n"
     ]
    }
   ],
   "source": [
    "# # ================= LOAD THRESHOLDS FROM CSV =================\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# from pathlib import Path\n",
    "\n",
    "# CSV_PATH = Path(\"/Users/mrinalseth13331/Downloads/cae_per_category_summary.csv\")\n",
    "# CAE_DIR = Path(\"saved_spatial_caes_simple\")\n",
    "# CAE_DIR.mkdir(exist_ok=True)\n",
    "# OUT_JSON = CAE_DIR / \"thresholds.json\"\n",
    "\n",
    "# category_list = [\n",
    "#     'bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', \n",
    "#     'leather', 'metal_nut', 'pill', 'screw', 'tile', \n",
    "#     'toothbrush', 'transistor', 'wood', 'zipper'\n",
    "# ]\n",
    "\n",
    "# df = pd.read_csv(CSV_PATH)\n",
    "# print(\"CSV columns:\", df.columns.tolist())\n",
    "\n",
    "# # find threshold column automatically\n",
    "# threshold_col = [c for c in df.columns if \"threshold\" in c.lower()][0]\n",
    "# cat_col = [c for c in df.columns if \"category\" in c.lower()][0]\n",
    "\n",
    "# thresholds = {}\n",
    "# missing = []\n",
    "\n",
    "# for cat in category_list:\n",
    "#     row = df[df[cat_col] == cat]\n",
    "#     if row.empty:\n",
    "#         print(\"Missing category in CSV:\", cat)\n",
    "#         missing.append(cat)\n",
    "#         continue\n",
    "#     thresholds[cat] = float(row[threshold_col].values[0])\n",
    "\n",
    "# print(\"\\nLoaded thresholds for:\")\n",
    "# for k,v in thresholds.items():\n",
    "#     print(f\"{k}: {v}\")\n",
    "\n",
    "# # Save as JSON for Gradio\n",
    "# with open(OUT_JSON, \"w\") as f:\n",
    "#     json.dump(thresholds, f, indent=2)\n",
    "\n",
    "# print(\"\\nSaved thresholds.json to:\", OUT_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802c1746-3356-494e-819d-b4625b9c11c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Gradio app: classifier → extractor → CAE → threshold decision =====\n",
    "\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import torch, torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights, resnet50, ResNet50_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CAE_DIR = Path(\"saved_spatial_caes_simple\")\n",
    "CLASSIFIER_CKPT = Path(\"best_classifier.pth\")\n",
    "LATENT_DIM = 100\n",
    "DEVICE_PREFERENCE = \"mps\"\n",
    "TOPK = 10\n",
    "category_list = [\n",
    "    'bottle','cable','capsule','carpet','grid','hazelnut',\n",
    "    'leather','metal_nut','pill','screw','tile',\n",
    "    'toothbrush','transistor','wood','zipper'\n",
    "]\n",
    "\n",
    "device = torch.device(\"mps\") if (DEVICE_PREFERENCE==\"mps\" and torch.backends.mps.is_available()) else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# -------- feature extractor (ResNet50 hooks) --------\n",
    "class ResNetFeatureExtractorFast(nn.Module):\n",
    "    def __init__(self, pretrained=True, device=None):\n",
    "        super().__init__()\n",
    "        w = ResNet50_Weights.DEFAULT if pretrained else None\n",
    "        self.model = resnet50(weights=w)\n",
    "        self.model.eval()\n",
    "        for p in self.model.parameters(): p.requires_grad = False\n",
    "        self.features = []\n",
    "        self.hooks = []\n",
    "        self.hooks.append(self.model.layer2[-1].register_forward_hook(self._hook))\n",
    "        self.hooks.append(self.model.layer3[-1].register_forward_hook(self._hook))\n",
    "        if device is not None: self.to(device)\n",
    "\n",
    "    def _hook(self, module, input, output):\n",
    "        self.features.append(output.detach())\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.features = []\n",
    "        with torch.no_grad(): _ = self.model(x)\n",
    "        out = []\n",
    "        tsize = self.features[0].shape[-2:]\n",
    "        for f in self.features:\n",
    "            f = F.avg_pool2d(f, 3, 1, 1)\n",
    "            f = F.interpolate(f, size=tsize, mode='bilinear')\n",
    "            out.append(f)\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "# -------- CAE --------\n",
    "class FeatCAE(nn.Module):\n",
    "    def __init__(self, in_channels=1536, latent_dim=100, is_bn=True):\n",
    "        super().__init__()\n",
    "        e = []\n",
    "        e += [nn.Conv2d(in_channels, (in_channels+2*latent_dim)//2, 1)]\n",
    "        if is_bn: e += [nn.BatchNorm2d((in_channels+2*latent_dim)//2)]\n",
    "        e += [nn.ReLU()]\n",
    "        e += [nn.Conv2d((in_channels+2*latent_dim)//2, 2*latent_dim, 1)]\n",
    "        if is_bn: e += [nn.BatchNorm2d(2*latent_dim)]\n",
    "        e += [nn.ReLU()]\n",
    "        e += [nn.Conv2d(2*latent_dim, latent_dim, 1)]\n",
    "        self.encoder = nn.Sequential(*e)\n",
    "\n",
    "        d = []\n",
    "        d += [nn.Conv2d(latent_dim, 2*latent_dim, 1)]\n",
    "        if is_bn: d += [nn.BatchNorm2d(2*latent_dim)]\n",
    "        d += [nn.ReLU()]\n",
    "        d += [nn.Conv2d(2*latent_dim, (in_channels+2*latent_dim)//2, 1)]\n",
    "        if is_bn: d += [nn.BatchNorm2d((in_channels+2*latent_dim)//2)]\n",
    "        d += [nn.ReLU()]\n",
    "        d += [nn.Conv2d((in_channels+2*latent_dim)//2, in_channels, 1)]\n",
    "        self.decoder = nn.Sequential(*d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# -------- extractor --------\n",
    "extractor = ResNetFeatureExtractorFast(pretrained=True, device=device)\n",
    "extractor.model.eval()\n",
    "\n",
    "# -------- classifier --------\n",
    "if not CLASSIFIER_CKPT.exists():\n",
    "    raise RuntimeError(\"best_classifier.pth not found.\")\n",
    "\n",
    "clf = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "clf.fc = nn.Linear(clf.fc.in_features, len(category_list))\n",
    "state = torch.load(CLASSIFIER_CKPT, map_location=device)\n",
    "if isinstance(state, dict) and \"model_state_dict\" in state:\n",
    "    clf.load_state_dict(state[\"model_state_dict\"])\n",
    "else:\n",
    "    clf.load_state_dict(state)\n",
    "clf.to(device).eval()\n",
    "\n",
    "# -------- load CAEs --------\n",
    "trained_caes = {}\n",
    "for cat in category_list:\n",
    "    ck = CAE_DIR / f\"cae_{cat}.pth\"\n",
    "    if ck.exists():\n",
    "        cae = FeatCAE(1536, LATENT_DIM)\n",
    "        cae.load_state_dict(torch.load(ck, map_location=device))\n",
    "        cae.to(device).eval()\n",
    "        trained_caes[cat] = cae\n",
    "    else:\n",
    "        print(\"Missing CAE:\", cat)\n",
    "\n",
    "# -------- load thresholds.json --------\n",
    "thr_file = CAE_DIR / \"thresholds.json\"\n",
    "if not thr_file.exists():\n",
    "    raise RuntimeError(\"thresholds.json missing.\")\n",
    "with open(thr_file,\"r\") as f:\n",
    "    thresholds = json.load(f)\n",
    "\n",
    "# -------- scoring --------\n",
    "def topk_score(seg, k=TOPK):\n",
    "    flat = seg.view(seg.size(0), -1)\n",
    "    k = min(k, flat.size(1))\n",
    "    vals = torch.topk(flat, k, dim=1).values\n",
    "    return vals.mean(dim=1)\n",
    "\n",
    "# -------- heat overlay --------\n",
    "def overlay_heat(img, heat, alpha=0.6):\n",
    "    import matplotlib.cm as cm\n",
    "    img = img.convert(\"RGB\").resize((224,224))\n",
    "    cmap = cm.get_cmap(\"jet\")\n",
    "    heat = (cmap(heat)[:,:,:3] * 255).astype(np.uint8)\n",
    "    return Image.blend(img, Image.fromarray(heat), alpha)\n",
    "\n",
    "# -------- pipeline --------\n",
    "def predict(img_pil):\n",
    "    x = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_idx = clf(x).argmax(1).item()\n",
    "    cat = category_list[pred_idx]\n",
    "\n",
    "    if cat not in trained_caes:\n",
    "        return None, None, f\"No CAE for {cat}\"\n",
    "\n",
    "    thr = thresholds[cat]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        f = extractor(x)\n",
    "        r = trained_caes[cat](f)\n",
    "        err = ((f - r)**2).mean(1, keepdim=True)\n",
    "        up = F.interpolate(err, (224,224), mode='bilinear')\n",
    "\n",
    "    heat = up.squeeze().cpu().numpy()\n",
    "    heat_norm = (heat - heat.min())/(heat.max()-heat.min()+1e-8)\n",
    "\n",
    "    score = float(topk_score(up).cpu())\n",
    "    anomaly = score >= thr\n",
    "\n",
    "    overlay = overlay_heat(img_pil, heat_norm)\n",
    "    text = f\"Category: {cat}\\nScore: {score:.6f}\\nThreshold: {thr:.6f}\\nAnomaly: {'YES' if anomaly else 'NO'}\"\n",
    "    return overlay, heat_norm, text\n",
    "\n",
    "# -------- Gradio UI --------\n",
    "iface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload image\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Overlay\"),\n",
    "        gr.Image(type=\"numpy\", label=\"Heatmap\"),\n",
    "        gr.Textbox(label=\"Result\")\n",
    "    ],\n",
    "    title=\"MVTec CAE-Based Anomaly Detection\"\n",
    ")\n",
    "\n",
    "iface.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ee530-98a1-4684-9900-2612cb98e8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
